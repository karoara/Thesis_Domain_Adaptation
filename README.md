# Conditioning Language Models for Domain Adaptation (Senior Thesis)

This repository contains the code for my senior thesis on a method for zero-shot domain adaptation. In simpler terms, this means getting a model to be able to perform a task well in domains that it does not train on (in practice, probably because little-to-no training data is available in those domains). All models here are implemented in Pytorch. Read the thesis [here](https://www.dropbox.com/s/qu3k4m6lou60u5b/Thesis_Final_Report.pdf?dl=0).

## About the Method

### Some Intuition

The way you interpret language when reading a horror film review is different from the way you do so when reading a restaurant review (for the former, the word "terrifying" might be used to indicate a positive experience; in the latter, that seems unlikely). Neural models used for a variety of language tasks might implicitly learn to recognize what domain an input sentence belongs to among those it trains on, and condition the way they treat its language accordingly. However, if we want a model to generalize well to some domain that it has not trained on, it might be tricky for the model to recognize how to treat language from that domain. It may have simply "memorized" how to treat language for the domains it has trained on - it has not explicitly learned how to do so based on the kind of domain it is dealing with. For my thesis, I attempted to address this by training models to modify the way they perform a task based on some information about the domain their input is from. 

## Problem Setting

The method I developed assumes that labeled training data for a desired task is available for a set of domains, and that some high-level information on these domains - and on others that we might want a model to generalize well to, but for which there is no training data - is also available. 

### The Conditioning Mechanism

In order to get models to generalize well to domains they do not train on, I 

### Experiments

## Running the Code

### Dependencies

### Running Experiments

Abstract: We consider a setting in which a language model - given access to some information about an inputâ€™s domain - is trained to learn a task over an entire distribution of domains, with the goal of generalizing to inputs from domains that are not in its training data. Drawing inspiration from existing methods outside our problem setting, we develop a mechanism that conditions an operation in a language model to modify its representation of an input based on information about a domain. This mechanism is meant to be trained jointly with the task- performing model, and makes few assumptions about the model architecture. We perform experiments in which we compare the performance of a model that is augmented with our mechanism to a baseline that is not for language modeling and sentiment analysis tasks. While the conditioning mechanism does not currently provide a performance improvement on real data, experiments with synthetic data suggest that it is capable of doing so, and that some fine-tuning and further experimentation may enable it to work better.
